[![CI](https://github.com/nogibjj/mini_project10_xueqing_wu/actions/workflows/cicd.yml/badge.svg)](https://github.com/nogibjj/mini_project10_xueqing_wu/actions/workflows/cicd.yml)

# Purpose
The goal of this project is to use PySpark to perform data processing (data transformation and querying) on a large dataset. 

# Functionality
The code does data processing with Spark SQL and transformations:

1. [E] Extract a dataset from a URL with CSV format.
1. [T] Transform the data by filtering to get it ready for analysis.
1. [L] Load the transformed data into a database table using Spark SQL.
1. [Q] Accept and execute SQL queries on the database to analyze and retrieve insights from the data.


# Steps
1. Revise Requirements.txt
2. Install PySpark to have dependency
3. Edit lib.py, main.py, test_main.py to have ETL and query
4. Create log output file

# Format Code
1. Format code: make format
1. Lint code: make lint
1. Test code: make test

# References
https://github.com/nogibjj/python-ruff-template 




